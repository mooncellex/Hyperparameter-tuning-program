{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d0df67e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, iterations=5000, degree=1):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "        self.degree = degree\n",
    "        self.poly = PolynomialFeatures(degree=self.degree)\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X_poly = self.poly.fit_transform(X)\n",
    "        self.weights = np.zeros(X_poly.shape[1])\n",
    "        self.bias = 0\n",
    "        \n",
    "        for _ in range(self.iterations):\n",
    "            model = np.dot(X_poly, self.weights) + self.bias\n",
    "            predictions = self.sigmoid(model)\n",
    "            \n",
    "            dw = np.dot(X_poly.T, (predictions - y)) / len(y)\n",
    "            db = np.sum(predictions - y) / len(y)\n",
    "            \n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_poly = self.poly.transform(X)\n",
    "        model = np.dot(X_poly, self.weights) + self.bias\n",
    "        predictions = self.sigmoid(model)\n",
    "        return [1 if i > 0.5 else 0 for i in predictions]\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {'learning_rate': self.learning_rate, 'iterations': self.iterations, 'degree': self.degree}\n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e58bc6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(self, n_estimators=100, max_depth=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # 确保X和y都是numpy数组以便于索引\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        for _ in range(self.n_estimators):\n",
    "            tree = DecisionTreeClassifier(max_depth=self.max_depth)\n",
    "            bootstrap_indices = np.random.randint(low=0, high=len(X), size=len(X))\n",
    "            X_bootstrap = X[bootstrap_indices]\n",
    "            y_bootstrap = y[bootstrap_indices]\n",
    "            tree.fit(X_bootstrap, y_bootstrap)\n",
    "            self.trees.append(tree)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        tree_preds = np.array([tree.predict(X) for tree in self.trees])\n",
    "        tree_preds = np.swapaxes(tree_preds, 0, 1)\n",
    "        majority_votes = np.array([np.bincount(tree_pred).argmax() for tree_pred in tree_preds])\n",
    "        return majority_votes\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        predictions = self.predict(X)\n",
    "        return accuracy_score(y, predictions)\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {'n_estimators': self.n_estimators, 'max_depth': self.max_depth}\n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4087562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "#from tensorflow.compat.v1.losses import sparse_softmax_cross_entropy\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "def create_model(n_features, n_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=n_features, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "class FCNNClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_features, n_classes):\n",
    "        self.n_features = n_features\n",
    "        self.n_classes = n_classes\n",
    "        self.build_fn = create_model\n",
    "        self.keras_model = self.build_fn(n_features, n_classes)\n",
    "        self.classifier = KerasClassifier(model=self.keras_model)\n",
    "\n",
    "    def fit(self, X, y, epochs=100, batch_size=10):\n",
    "        self.model.fit(X, y, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = self.model.predict(X)\n",
    "        return np.argmax(y_pred, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e5f14912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# XGBoost 简化版\n",
    "class XGBoostSimple:\n",
    "    def __init__(self, n_estimators=5):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.stumps = []\n",
    "        self.stump_weights = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        sample_weights = np.full(X.shape[0], (1 / X.shape[0]))\n",
    "        for _ in range(self.n_estimators):\n",
    "            stump = DecisionTreeClassifier(max_depth=1)\n",
    "            stump.fit(X, y, sample_weight=sample_weights)\n",
    "            stump_pred = stump.predict(X)\n",
    "            incorrect = (stump_pred != y)\n",
    "            error = np.mean(np.average(incorrect, weights=sample_weights, axis=0))\n",
    "            stump_weight = 0.5 * np.log((1 - error) / (error + 1e-10))\n",
    "            sample_weights *= np.exp(-stump_weight * y * stump_pred)\n",
    "            sample_weights /= np.sum(sample_weights)\n",
    "            self.stumps.append(stump)\n",
    "            self.stump_weights.append(stump_weight)\n",
    "\n",
    "    def predict(self, X):\n",
    "        stump_preds = np.array([stump_weight * stump.predict(X) for stump, stump_weight in zip(self.stumps, self.stump_weights)])\n",
    "        return np.sign(np.sum(stump_preds, axis=0))\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fe9cd8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression best score: 0.011861771257788728\n",
      "RandomForestClassifier best score: 0.2794113393301014\n",
      "KerasClassifier best score: 0.31985710072255036\n",
      "XGBClassifier best score: 0.3228908081976596\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import f1_score,make_scorer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 加载数据\n",
    "train_df = pd.read_csv(r'C:\\Users\\mooncell\\project3\\train.csv')\n",
    "test_df = pd.read_csv(r'C:\\Users\\mooncell\\project3\\test.csv')\n",
    "\n",
    "# 数据预处理\n",
    "# 分离特征和标签\n",
    "X_train = train_df.drop(['id', 'label'], axis=1)\n",
    "y_train = train_df['label']\n",
    "X_test = test_df.drop('id', axis=1)\n",
    "\n",
    "# 使用 LabelEncoder 对 y_train 进行编码\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "# 定义数值和分类特征\n",
    "numeric_features = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
    "                    'chlorides','free sulfur dioxide','total sulfur dioxide','density','pH','sulphates','alcohol']\n",
    "categorical_features = []\n",
    "\n",
    "# 将分类特征转换为字符串\n",
    "X_train[categorical_features] = X_train[categorical_features].astype(str)\n",
    "X_test[categorical_features] = X_test[categorical_features].astype(str)\n",
    "\n",
    "\n",
    "# 创建预处理转换器\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# 定义评分函数\n",
    "f1_scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# 合并预处理步骤\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# 创建模型字典\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'RandomForestClassifier': RandomForest(),\n",
    "    #'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "    #'KNNClassifier': KNNClassifier(),\n",
    "    'KerasClassifier':KerasClassifier(model=create_model, epochs=100, batch_size=10, verbose=0),\n",
    "    'XGBClassifier': XGBClassifier()\n",
    "}\n",
    "\n",
    "# 创建参数网格字典\n",
    "param_grids = {\n",
    "    'LogisticRegression': { 'classifier__learning_rate': [0.001, 0.01, 0.1], 'classifier__iterations': [100, 1000, 10000],'classifier__degree':[3]},\n",
    "    'RandomForestClassifier': {'classifier__n_estimators': [100, 200], 'classifier__max_depth': [None, 10, 20]},\n",
    "    #'GradientBoostingClassifier': {'classifier__n_estimators': [100, 200], 'classifier__learning_rate': [0.01, 0.1, 1]},\n",
    "    #'KNNClassifier': {'classifier__k': [3, 5, 7, 9]},\n",
    "    'KerasClassifier': {'classifier__model__n_features': [X_train.shape[1]],'classifier__model__n_classes': [len(np.unique(y_train))],\n",
    "        'classifier__batch_size': [10, 20, 50],'classifier__epochs': [10, 50, 100]},\n",
    "    'XGBClassifier': { 'classifier__n_estimators': [100, 200, 300], 'classifier__learning_rate': [0.01, 0.1, 0.3], 'classifier__max_depth': [3, 4, 5]}\n",
    "}\n",
    "\n",
    "# 比较模型性能\n",
    "best_models = {}\n",
    "for model_name, model in models.items():\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('classifier', model)])\n",
    "    param_grid = param_grids[model_name]\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, scoring=f1_scorer, cv=5)\n",
    "    grid_search.fit(X_train, y_train_encoded)\n",
    "    best_models[model_name] = grid_search.best_estimator_\n",
    "    print(f'{model_name} best score: {grid_search.best_score_}')\n",
    "\n",
    "# 使用最佳模型进行预测\n",
    "for model_name, model in best_models.items():\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    # 将预测的编码标签转换回原始标签\n",
    "    y_test_pred_original = label_encoder.inverse_transform(y_test_pred)\n",
    "    # 生成提交文件\n",
    "    submission = pd.DataFrame({'id': test_df['id'], 'label': y_test_pred})\n",
    "    submission.to_csv(fr'C:\\Users\\mooncell\\project3\\sample_submission_{model_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1b084817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier best score: 0.011861771257788728\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import f1_score,make_scorer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 加载数据\n",
    "train_df = pd.read_csv(r'C:\\Users\\mooncell\\project3\\train.csv')\n",
    "test_df = pd.read_csv(r'C:\\Users\\mooncell\\project3\\test.csv')\n",
    "\n",
    "# 数据预处理\n",
    "# 分离特征和标签\n",
    "X_train = train_df.drop(['id', 'label'], axis=1)\n",
    "y_train = train_df['label']\n",
    "X_test = test_df.drop('id', axis=1)\n",
    "\n",
    "# 使用 LabelEncoder 对 y_train 进行编码\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "# 定义数值和分类特征\n",
    "numeric_features = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
    "                    'chlorides','free sulfur dioxide','total sulfur dioxide','density','pH','sulphates','alcohol']\n",
    "categorical_features = []\n",
    "\n",
    "# 将分类特征转换为字符串\n",
    "X_train[categorical_features] = X_train[categorical_features].astype(str)\n",
    "X_test[categorical_features] = X_test[categorical_features].astype(str)\n",
    "\n",
    "\n",
    "# 创建预处理转换器\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# 定义评分函数\n",
    "f1_scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# 合并预处理步骤\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# 创建模型字典\n",
    "models = {\n",
    "    'XGBClassifier': XGBoostSimple()\n",
    "}\n",
    "\n",
    "# 创建参数网格字典\n",
    "param_grids = {\n",
    "    'XGBClassifier': { 'classifier__n_estimators': [100, 200, 300], 'classifier__learning_rate': [0.01, 0.1, 0.3], 'classifier__reg_lambda': [3, 4, 5]}\n",
    "}\n",
    "\n",
    "# 比较模型性能\n",
    "best_models = {}\n",
    "for model_name, model in models.items():\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('classifier', model)])\n",
    "    param_grid = param_grids[model_name]\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, scoring=f1_scorer, cv=5)#,error_score='raise')\n",
    "    grid_search.fit(X_train, y_train_encoded)\n",
    "    best_models[model_name] = grid_search.best_estimator_\n",
    "    print(f'{model_name} best score: {grid_search.best_score_}')\n",
    "\n",
    "# 使用最佳模型进行预测\n",
    "for model_name, model in best_models.items():\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    # 将浮点数预测转换为整数标签\n",
    "    y_test_pred_int = np.argmax(y_test_pred, axis=1) if y_test_pred.ndim > 1 else y_test_pred.astype(int)\n",
    "    \n",
    "    # 将预测的编码标签转换回原始标签\n",
    "    y_test_pred_original = label_encoder.inverse_transform(y_test_pred_int)\n",
    "    # 生成提交文件\n",
    "    submission = pd.DataFrame({'id': test_df['id'], 'label': y_test_pred_original})\n",
    "    submission.to_csv(fr'C:\\Users\\mooncell\\project3\\sample_submission_{model_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6a86d50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1125,)\n",
      "(474,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_encoded.shape)\n",
    "print(y_test_pred_original.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90310a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class KNNClassifier:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = [self._predict(x) for x in X]\n",
    "        return np.array(y_pred)\n",
    "\n",
    "    def _predict(self, x):\n",
    "        # 计算距离\n",
    "        distances = [np.sqrt(np.sum((x_train - x) ** 2)) for x_train in self.X_train]\n",
    "        # 获取k个最近样本的索引\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        # 获取这些样本的标签\n",
    "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "        # 多数投票\n",
    "        most_common = Counter(k_nearest_labels).most_common(1)\n",
    "        return most_common[0][0]\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {'k': self.k}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
